{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307b028-4f29-4183-8ef5-00bf859ca494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NECESSARY LIBRARIES INSTALATION.\n",
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130bcfc-0e36-44fb-825a-089dd9703bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50cda3-9d68-4c78-b090-417226a4aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d879e-f96f-4edd-bc33-24e916d36fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c5a1d-bf09-4984-bbf3-b4df924a5f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DIVIDING THE DATASET INTO TRAIN TEST AND VALIDATE\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "source_folder = r\"C:\\Users\\nites\\Desktop\\SVPCNN\"  # Root folder (A, B, ..., Z)\n",
    "train_folder = r\"C:\\Users\\nites\\Desktop\\svp_train\"  # Already exists\n",
    "test_folder = r\"C:\\Users\\nites\\Desktop\\svp_test\"  # Already exists\n",
    "validate_folder = r\"C:\\Users\\nites\\Desktop\\svp_validate\"  # Already exists\n",
    "\n",
    "# Split ratio (70% train, 15% test, 15% validate)\n",
    "split_ratio = (0.7, 0.15, 0.15)\n",
    "\n",
    "# Ensure destination subfolders (real/forged) exist\n",
    "for folder in [train_folder, test_folder, validate_folder]:\n",
    "    for subfolder in [\"real\", \"forged\"]:\n",
    "        os.makedirs(os.path.join(folder, subfolder), exist_ok=True)\n",
    "\n",
    "# Process each letter folder (A, B, ..., Z)\n",
    "for letter in os.listdir(source_folder):\n",
    "    letter_path = os.path.join(source_folder, letter)\n",
    "    \n",
    "    # Skip non-directories (e.g., files in SVPCNN)\n",
    "    if not os.path.isdir(letter_path):\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing: {letter}\")\n",
    "    \n",
    "    # Process real and forged subfolders\n",
    "    for category in [\"real\", \"forged\"]:\n",
    "        category_path = os.path.join(letter_path, category)\n",
    "        \n",
    "        # Skip if subfolder doesn't exist\n",
    "        if not os.path.exists(category_path):\n",
    "            print(f\"Skipping missing folder: {category_path}\")\n",
    "            continue\n",
    "        \n",
    "        # List all files\n",
    "        files = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f))]\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        # Split files\n",
    "        total = len(files)\n",
    "        train_end = int(split_ratio[0] * total)\n",
    "        test_end = train_end + int(split_ratio[1] * total)\n",
    "        \n",
    "        train_files = files[:train_end]\n",
    "        test_files = files[train_end:test_end]\n",
    "        validate_files = files[test_end:]\n",
    "        \n",
    "        # Move files to destination folders\n",
    "        def move_files(file_list, destination):\n",
    "            for file in file_list:\n",
    "                src = os.path.join(category_path, file)\n",
    "                dest = os.path.join(destination, category, file)\n",
    "                shutil.move(src, dest)\n",
    "                print(f\"Moved: {file} âž” {dest}\")\n",
    "        \n",
    "        move_files(train_files, train_folder)\n",
    "        move_files(test_files, test_folder)\n",
    "        move_files(validate_files, validate_folder)\n",
    "\n",
    "print(\"All files split and moved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a8da7-a329-4c3b-b36a-06eeebde61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETING ALL THE UNNECCESARY FOLDERS AND ORGANIZING.\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the paths to your directories\n",
    "svp_train_path = \"C:/Users/nites/Desktop/svp_train\"  # Replace with your actual path\n",
    "svp_test_path = \"C:/Users/nites/Desktop/svp_test\"    # Replace with your actual path\n",
    "svp_validate_path = \"C:/Users/nites/Desktop/svp_validate\"  # Replace with your actual path\n",
    "\n",
    "# List of directories to process\n",
    "directories = [svp_train_path, svp_test_path, svp_validate_path]\n",
    "\n",
    "# Folders to keep\n",
    "folders_to_keep = {'forged', 'real'}\n",
    "\n",
    "# Function to delete unwanted folders\n",
    "def clean_directory(directory):\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        if os.path.isdir(item_path) and item not in folders_to_keep:\n",
    "            print(f\"Deleting: {item_path}\")\n",
    "            shutil.rmtree(item_path)\n",
    "        else:\n",
    "            print(f\"Keeping: {item_path}\")\n",
    "\n",
    "# Process each directory\n",
    "for directory in directories:\n",
    "    if os.path.exists(directory):\n",
    "        print(f\"Processing: {directory}\")\n",
    "        clean_directory(directory)\n",
    "    else:\n",
    "        print(f\"Directory not found: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513ed05-4926-4f6a-be4e-858d26c95746",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595140c7-c025-462b-bced-e9a440eb6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING THE DATASET SPLITTING INTO STANDARD 70,15,15 SPLIT FROM THE EARLIER IMPROPER SPLIT.\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths (modify as needed)\n",
    "base_dir = r\"C:\\Users\\nites\\Desktop\\disdataset\"  # Folder containing svp_train, svp_test, svp_validate\n",
    "new_dir = r\"C:\\Users\\nites\\Desktop\\redisdataset\"  # New folder for 70-15-15 split\n",
    "\n",
    "# Create new directory structure\n",
    "os.makedirs(os.path.join(new_dir, \"train\", \"real\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(new_dir, \"train\", \"forged\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(new_dir, \"test\", \"real\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(new_dir, \"test\", \"forged\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(new_dir, \"validate\", \"real\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(new_dir, \"validate\", \"forged\"), exist_ok=True)\n",
    "\n",
    "# Collect all images from original splits\n",
    "real_images = []\n",
    "forged_images = []\n",
    "\n",
    "original_splits = {\n",
    "    \"svp_train\": \"train\",\n",
    "    \"svp_test\": \"test\", \n",
    "    \"svp_validate\": \"validate\"\n",
    "}\n",
    "\n",
    "for orig_split, _ in original_splits.items():\n",
    "    real_path = os.path.join(base_dir, orig_split, \"real\")\n",
    "    forged_path = os.path.join(base_dir, orig_split, \"forged\")\n",
    "    \n",
    "    if os.path.exists(real_path):\n",
    "        real_images.extend([os.path.join(real_path, f) for f in os.listdir(real_path)])\n",
    "    if os.path.exists(forged_path):\n",
    "        forged_images.extend([os.path.join(forged_path, f) for f in os.listdir(forged_path)])\n",
    "\n",
    "# Verify we found files\n",
    "if not real_images or not forged_images:\n",
    "    raise FileNotFoundError(\"No images found in the specified paths!\")\n",
    "\n",
    "# Shuffle to ensure randomness\n",
    "random.shuffle(real_images)\n",
    "random.shuffle(forged_images)\n",
    "\n",
    "# Split into 70-15-15 ratio\n",
    "def split_data(images, train_ratio=0.7, test_ratio=0.15):\n",
    "    train_size = int(len(images) * train_ratio)\n",
    "    test_size = int(len(images) * test_ratio)\n",
    "    \n",
    "    train = images[:train_size]\n",
    "    test = images[train_size : train_size + test_size]\n",
    "    validate = images[train_size + test_size:]\n",
    "    \n",
    "    return train, test, validate\n",
    "\n",
    "# Split both classes\n",
    "real_train, real_test, real_validate = split_data(real_images)\n",
    "forged_train, forged_test, forged_validate = split_data(forged_images)\n",
    "\n",
    "# Copy files to new structure\n",
    "def copy_files(files, split, label):\n",
    "    for file in files:\n",
    "        dest = os.path.join(new_dir, split, label, os.path.basename(file))\n",
    "        shutil.copy2(file, dest)\n",
    "\n",
    "print(\"Redistributing files...\")\n",
    "copy_files(real_train, \"train\", \"real\")\n",
    "copy_files(forged_train, \"train\", \"forged\")\n",
    "copy_files(real_test, \"test\", \"real\") \n",
    "copy_files(forged_test, \"test\", \"forged\")\n",
    "copy_files(real_validate, \"validate\", \"real\")\n",
    "copy_files(forged_validate, \"validate\", \"forged\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nRedistribution complete!\")\n",
    "print(f\"Total real signatures: {len(real_images)}\")\n",
    "print(f\"Total forged signatures: {len(forged_images)}\")\n",
    "print(f\"\\nNew splits:\")\n",
    "print(f\"Train: {len(real_train) + len(forged_train)} samples\")\n",
    "print(f\"Test: {len(real_test) + len(forged_test)} samples\")\n",
    "print(f\"Validate: {len(real_validate) + len(forged_validate)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e450b-442a-45e7-8ca7-44507d68fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT OF TRAIN IMAGES BEFORE PREPROCESSING.\n",
    "import os\n",
    "\n",
    "train_real_dir = r\"C:\\Users\\nites\\Desktop\\redisdataset\\train\\real\"\n",
    "train_forged_dir =r\"C:\\Users\\nites\\Desktop\\redisdataset\\train\\forged\"\n",
    "\n",
    "print(f\"Number of real signatures: {len(os.listdir(train_real_dir))}\")\n",
    "print(f\"Number of forged signatures: {len(os.listdir(train_forged_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb033ac-c344-4c9e-bc16-71afaa383e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT OF TEST IMAGES BEFORE PREPROCESSING.\n",
    "import os\n",
    "\n",
    "test_real_dir = r\"C:/Users/nites/Desktop/redisdataset\\test\\real\"\n",
    "test_forged_dir = r\"C:/Users/nites/Desktop/redisdataset\\test\\forged\"\n",
    "\n",
    "print(f\"Number of real signatures: {len(os.listdir(test_real_dir))}\")\n",
    "print(f\"Number of forged signatures: {len(os.listdir(test_forged_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941f46e-9557-4a5d-83a2-51d819be6ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT OF VALIDATE IMAGES BEFORE PREPROCESSING.\n",
    "import os\n",
    "\n",
    "val_real_dir = r\"C:/Users/nites/Desktop/redisdataset\\validate\\real\"\n",
    "val_forged_dir = r\"C:/Users/nites/Desktop/redisdataset\\validate\\forged\"\n",
    "\n",
    "print(f\"Number of real signatures: {len(os.listdir(val_real_dir))}\")\n",
    "print(f\"Number of forged signatures: {len(os.listdir(val_forged_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c46c0-1ed9-42ac-b143-a45e4901d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432704ae-dd13-4043-b332-cb1fd781b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRE-PROCESSING OF THE DATASET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048b39f-4b0a-4b2d-9803-1ce3ac716418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import albumentations as A\n",
    "from skimage.filters import unsharp_mask\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "class EnhancedSignatureProcessor:\n",
    "    def __init__(self):\n",
    "        self.img_size = (224, 224)\n",
    "        self.sharpen_params = {'radius': 1, 'amount': 1.5}\n",
    "        \n",
    "        # Augmentation pipeline\n",
    "        self.train_aug = A.Compose([\n",
    "            A.Affine(\n",
    "                scale=(0.95, 1.05),\n",
    "                rotate=(-2, 2),\n",
    "                shear=(-1, 1),  \n",
    "                p=0.7\n",
    "            ),\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(1, 2)),\n",
    "                A.MotionBlur(blur_limit=3),\n",
    "            ], p=0.4),\n",
    "            A.OneOf([\n",
    "                A.ISONoise(color_shift=(0.01, 0.03)),\n",
    "                A.RandomGamma(gamma_limit=(90, 110)),\n",
    "            ], p=0.3),\n",
    "            A.ElasticTransform(alpha=0.5, sigma=10, p=0.2),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1, 0.1),\n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.3\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "    def enhanced_preprocess(self, img):\n",
    "        \"\"\"Advanced preprocessing pipeline\"\"\"\n",
    "        # 1. Illumination normalization\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        lab = cv2.merge((l,a,b))\n",
    "        img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        # 2. Edge-preserving denoising\n",
    "        denoised = cv2.fastNlMeansDenoisingColored(img, None, h=7, \n",
    "                                                 templateWindowSize=7, \n",
    "                                                 searchWindowSize=21)\n",
    "        \n",
    "        # 3. Adaptive thresholding\n",
    "        gray = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY_INV, 31, 2)\n",
    "        \n",
    "        # 4. Stroke normalization\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2,2))\n",
    "        normalized = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # 5. Context-aware sharpening\n",
    "        sharpened = unsharp_mask(normalized, **self.sharpen_params)\n",
    "        sharpened = (sharpened * 255).astype(np.uint8)\n",
    "        \n",
    "        # 6. Size normalization\n",
    "        processed = self._resize_preserve_aspect(sharpened)\n",
    "        return cv2.cvtColor(processed, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    def _resize_preserve_aspect(self, img):\n",
    "        h, w = img.shape\n",
    "        scale = min(self.img_size[0]/h, self.img_size[1]/w)\n",
    "        new_h, new_w = int(h*scale), int(w*scale)\n",
    "        resized = cv2.resize(img, (new_w, new_h))\n",
    "        \n",
    "        delta_w = self.img_size[1] - new_w\n",
    "        delta_h = self.img_size[0] - new_h\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "        return cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                cv2.BORDER_CONSTANT, value=255)\n",
    "\n",
    "    def process_image(self, args):\n",
    "        input_path, output_path, is_training = args\n",
    "        try:\n",
    "            img = cv2.imread(input_path)\n",
    "            if img is None:\n",
    "                return False\n",
    "                \n",
    "            processed = self.enhanced_preprocess(img)\n",
    "            cv2.imwrite(output_path, processed)\n",
    "            \n",
    "            if is_training:\n",
    "                base_name = os.path.splitext(output_path)[0]\n",
    "                for i in range(4):\n",
    "                    augmented = self.train_aug(image=processed)['image']\n",
    "                    cv2.imwrite(f\"{base_name}_aug{i}.jpg\", augmented)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {input_path}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "def check_class_balance(input_dir):\n",
    "    class_counts = {}\n",
    "    for class_name in ['real', 'forged']:\n",
    "        class_dir = os.path.join(input_dir, 'train', class_name)\n",
    "        count = len([f for f in os.listdir(class_dir) \n",
    "                   if f.lower().endswith(('.png','.jpg','.jpeg'))])\n",
    "        class_counts[class_name] = count\n",
    "    \n",
    "    print(\"\\n=== CLASS DISTRIBUTION ===\")\n",
    "    print(f\"Real signatures: {class_counts['real']}\")\n",
    "    print(f\"Forged signatures: {class_counts['forged']}\")\n",
    "    \n",
    "    imbalance = abs(class_counts['real'] - class_counts['forged'])/min(class_counts.values())\n",
    "    if imbalance > 0.2:\n",
    "        print(\"\\nWarning: Significant class imbalance detected!\")\n",
    "    return class_counts\n",
    "\n",
    "def process_dataset(processor, input_base, output_base, num_workers=4):\n",
    "    tasks = []\n",
    "    \n",
    "    for phase in ['train', 'test', 'val']:\n",
    "        for class_name in ['real', 'forged']:\n",
    "            input_dir = os.path.join(input_base, phase, class_name)\n",
    "            output_dir = os.path.join(output_base, f\"svp_{phase}\", class_name)\n",
    "            \n",
    "            if not os.path.exists(input_dir):\n",
    "                continue\n",
    "                \n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            is_training = (phase == 'train')\n",
    "            \n",
    "            images = [f for f in os.listdir(input_dir) \n",
    "                     if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "            \n",
    "            for img_name in images:\n",
    "                tasks.append((\n",
    "                    os.path.join(input_dir, img_name),\n",
    "                    os.path.join(output_dir, os.path.splitext(img_name)[0] + \".jpg\"),\n",
    "                    is_training\n",
    "                ))\n",
    "    \n",
    "    with Pool(processes=min(num_workers, cpu_count())) as pool:\n",
    "        results = list(tqdm(pool.imap(processor.process_image, tasks), \n",
    "                      total=len(tasks), desc=\"Processing Dataset\"))\n",
    "    \n",
    "    success_rate = sum(results)/len(results)\n",
    "    print(f\"\\nProcessing completed with {success_rate:.1%} success rate\")\n",
    "\n",
    "def verify_output_quality(output_dir):\n",
    "    print(\"\\n=== OUTPUT QUALITY CHECK ===\")\n",
    "    for phase in ['train', 'test', 'val']:\n",
    "        for class_name in ['real', 'forged']:\n",
    "            dir_path = os.path.join(output_dir, f\"svp_{phase}\", class_name)\n",
    "            if not os.path.exists(dir_path):\n",
    "                continue\n",
    "                \n",
    "            samples = [f for f in os.listdir(dir_path) if f.endswith('.jpg')][:3]\n",
    "            print(f\"\\nSample outputs from {phase}/{class_name}:\")\n",
    "            for sample in samples:\n",
    "                img = cv2.imread(os.path.join(dir_path, sample))\n",
    "                print(f\"  {sample}: {'Valid' if img is not None else 'Corrupt'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    desktop = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    input_dir = os.path.join(desktop, \"redisdataset\")\n",
    "    output_dir = os.path.join(desktop, \"svp_processed_enhanced\")\n",
    "    \n",
    "    processor = EnhancedSignatureProcessor()\n",
    "    check_class_balance(input_dir)\n",
    "    process_dataset(processor, input_dir, output_dir)\n",
    "    verify_output_quality(output_dir)\n",
    "    \n",
    "    print(\"\\nProcessing complete! Enhanced dataset saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e2d0b-5d5e-45ed-b573-48b0131bb6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT OF TRAIN IMAGES AFTER PREPROCESSING AND AUGMENTING.\n",
    "import os\n",
    "\n",
    "train_real_dir = r\"C:/Users/nites/Desktop/svp_processed/svp_train/real\"\n",
    "train_forged_dir = r\"C:/Users/nites/Desktop/svp_processed/svp_train/forged\"\n",
    "\n",
    "print(f\"Number of real signatures: {len(os.listdir(train_real_dir))}\")\n",
    "print(f\"Number of forged signatures: {len(os.listdir(train_forged_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d0307-d5c2-4942-8e90-63f3202bfe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT OF TEST IMAGES AFTER PREPROCESSING.\n",
    "import os\n",
    "\n",
    "test_real_dir = r\"C:/Users/nites/Desktop/svp_processed/svp_test/real\"\n",
    "test_forged_dir = r\"C:/Users/nites/Desktop/svp_processed/svp_test/forged\"\n",
    "\n",
    "print(f\"Number of real signatures: {len(os.listdir(test_real_dir))}\")\n",
    "print(f\"Number of forged signatures: {len(os.listdir(test_forged_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed187ff-c746-4b77-adc2-d0adf0501d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNT OF VALIDATE IMAGES AFTER PREPROCESSING.\n",
    "import os\n",
    "\n",
    "val_real_dir = r\"C:/Users/nites/Desktop/svp_processed/svp_validate/real\"\n",
    "val_forged_dir = r\"C:/Users/nites/Desktop/svp_processed/svp_validate/forged\"\n",
    "\n",
    "print(f\"Number of real signatures: {len(os.listdir(val_real_dir))}\")\n",
    "print(f\"Number of forged signatures: {len(os.listdir(val_forged_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628a9b2-61fe-44af-8ccd-92f10dd73e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAYING THE IMAGES AFTER PREPROCESSING THROUGH VISUALIZATION OF PREPROCESSED AND AUGMENTED DATA OF ANY RANDOMLY CHOOSEN IMAGE IN THE DATASET...\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from skimage.filters import unsharp_mask\n",
    "\n",
    "def process_and_visualize(image_path):\n",
    "    \"\"\"Enhanced visualization of preprocessing and augmentations\"\"\"\n",
    "    # 1. Load original image\n",
    "    original = cv2.imread(image_path)\n",
    "    if original is None:\n",
    "        print(f\"Error: Could not load image from {image_path}\")\n",
    "        return\n",
    "    \n",
    "    original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 2. Enhanced preprocessing function\n",
    "    def preprocess(img):\n",
    "        # Noise reduction\n",
    "        denoised = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "        \n",
    "        # Adaptive thresholding\n",
    "        gray = cv2.cvtColor(denoised, cv2.COLOR_RGB2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                      cv2.THRESH_BINARY_INV, 31, 7)\n",
    "        \n",
    "        # Sharpening\n",
    "        sharpened = unsharp_mask(thresh, radius=1.5, amount=2.0)\n",
    "        sharpened = (sharpened * 255).astype(np.uint8)\n",
    "        \n",
    "        # Morphological cleanup\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "        cleaned = cv2.morphologyEx(sharpened, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Resize and convert to RGB\n",
    "        resized = cv2.resize(cleaned, (224, 224))\n",
    "        return cv2.cvtColor(resized, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # 3. Apply preprocessing\n",
    "    preprocessed = preprocess(original)\n",
    "\n",
    "    # 4. Define complete augmentation pipeline\n",
    "    augmentations = A.Compose([\n",
    "        A.Rotate(limit=3, p=0.5),\n",
    "        A.ElasticTransform(alpha=1.2, sigma=20, p=0.4),\n",
    "        A.OpticalDistortion(distort_limit=0.2, shift_limit=0.1, p=0.3),\n",
    "        A.GaussianBlur(blur_limit=(1, 3), p=0.3),\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=(-0.15, 0.15),\n",
    "            contrast_limit=(-0.15, 0.15), p=0.4),\n",
    "        A.GridDistortion(p=0.2),\n",
    "        A.CoarseDropout(max_holes=8, max_height=10, max_width=10, p=0.3),\n",
    "    ])\n",
    "\n",
    "    # 5. Generate 6 augmented versions\n",
    "    augmented_images = []\n",
    "    for _ in range(6):\n",
    "        augmented = augmentations(image=preprocessed)['image']\n",
    "        augmented_images.append(augmented)\n",
    "\n",
    "    # 6. Display results in grid layout\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # Original\n",
    "    plt.subplot(2, 4, 1)\n",
    "    plt.imshow(original)\n",
    "    plt.title(\"Original\\n(Original Input)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Preprocessed\n",
    "    plt.subplot(2, 4, 2)\n",
    "    plt.imshow(preprocessed)\n",
    "    plt.title(\"Preprocessed\\n(After Enhancement)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Augmentations\n",
    "    for i, img in enumerate(augmented_images, 3):\n",
    "        plt.subplot(2, 4, i)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Augmented #{i-2}\\n(Random Combination)\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = r\"C:\\Users\\nites\\Desktop\\redisdataset\\train\\real\\original_21_1.png\"  \n",
    "    process_and_visualize(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036e760-3df0-411a-b93b-b84669f74e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. AUC-ROC (Area Under the Curve - Receiver Operating Characteristic)\n",
    "# Ideal Value: Higher is better (Close to 1.0).\n",
    "\n",
    "# 2. Loss (Binary Cross-Entropy)\n",
    "# Ideal Value: Lower is better (Close to 0).\n",
    "\n",
    "# 3. Precision\n",
    "# Ideal Value: Higher is better (Close to 1.0).\n",
    "\n",
    "# 4. Recall (Sensitivity)\n",
    "# Ideal Value: Higher is better (Close to 1.0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a996d40-ab96-4108-86d9-7c4e1b3b6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tf-keras-vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3662774-ad62-424c-a6c9-da589046d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers, regularizers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# Set all seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "def create_data_generators():\n",
    "    \"\"\"Create enhanced data generators with validation split\"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.9, 1.1],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    return train_datagen, test_datagen\n",
    "\n",
    "def load_data_with_validation(data_dir=\"C:/Users/nites/Desktop/svp_processed\"):\n",
    "    \"\"\"Load data with proper validation split\"\"\"\n",
    "    data_dir = os.path.expanduser(data_dir)\n",
    "    \n",
    "    train_datagen, test_datagen = create_data_generators()\n",
    "    \n",
    "    # Training generator (80% of training data)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'svp_train'),\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        color_mode='rgb',\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Validation generator (20% of training data)\n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'svp_train'),\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        color_mode='rgb',\n",
    "        subset='validation',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Test generator\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'svp_test'),\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        color_mode='rgb',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Verify data loading\n",
    "    print(\"\\n=== DATA VERIFICATION ===\")\n",
    "    print(f\"Training samples: {train_generator.samples}\")\n",
    "    print(f\"Validation samples: {val_generator.samples}\")\n",
    "    print(f\"Test samples: {test_generator.samples}\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    print(\"\\nClass indices:\", train_generator.class_indices)\n",
    "    print(\"Training class counts:\", np.bincount(train_generator.classes))\n",
    "    print(\"Validation class counts:\", np.bincount(val_generator.classes))\n",
    "    print(\"Test class counts:\", np.bincount(test_generator.classes))\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "def build_optimized_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"Build optimized hybrid model with fine-tuning capability\"\"\"\n",
    "    # Load pre-trained EfficientNet\n",
    "    base_model = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze initial layers\n",
    "    for layer in base_model.layers[:100]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Unfreeze later layers\n",
    "    for layer in base_model.layers[100:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Create new model with more sophisticated architecture\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = base_model(inputs)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Custom optimizer configuration with warmup\n",
    "    optimizer = optimizers.Adam(\n",
    "        learning_rate=0.0001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        amsgrad=True\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "            tf.keras.metrics.AUC(name='auc'),\n",
    "            tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "            tf.keras.metrics.TruePositives(name='tp'),\n",
    "            tf.keras.metrics.FalsePositives(name='fp'),\n",
    "            tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "            tf.keras.metrics.FalseNegatives(name='fn')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_enhanced_callbacks():\n",
    "    \"\"\"Return optimized callbacks with model checkpointing\"\"\"\n",
    "    return [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_auc',\n",
    "            patience=15,\n",
    "            mode='max',\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            'best_model.keras',\n",
    "            monitor='val_auc',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.TensorBoard(\n",
    "            log_dir='./logs',\n",
    "            histogram_freq=1,\n",
    "            update_freq='epoch'\n",
    "        ),\n",
    "        callbacks.CSVLogger('training_log.csv')\n",
    "    ]\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training metrics with enhanced visualization\"\"\"\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Over Epochs', pad=10)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Over Epochs', pad=10)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot AUC\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(history.history['auc'], label='Train AUC')\n",
    "    plt.plot(history.history['val_auc'], label='Validation AUC')\n",
    "    plt.title('ROC AUC Over Epochs', pad=10)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Precision-Recall AUC\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.plot(history.history['prc'], label='Train PR AUC')\n",
    "    plt.plot(history.history['val_prc'], label='Validation PR AUC')\n",
    "    plt.title('PR AUC Over Epochs', pad=10)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('PR AUC')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Precision\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.plot(history.history['precision'], label='Train Precision')\n",
    "    plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "    plt.title('Precision Over Epochs', pad=10)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Recall\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.plot(history.history['recall'], label='Train Recall')\n",
    "    plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "    plt.title('Recall Over Epochs', pad=10)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, test_generator):\n",
    "    \"\"\"Comprehensive model evaluation with enhanced metrics\"\"\"\n",
    "    print(\"\\n=== FINAL EVALUATION ===\")\n",
    "    \n",
    "    # Load best weights\n",
    "    if os.path.exists('best_model.keras'):\n",
    "        model = models.load_model('best_model.keras')\n",
    "        print(\"Loaded best saved model for evaluation\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    results = model.evaluate(test_generator, verbose=0)\n",
    "    metrics = {\n",
    "        'Test Loss': results[0],\n",
    "        'Test Accuracy': results[1],\n",
    "        'Test Precision': results[2],\n",
    "        'Test Recall': results[3],\n",
    "        'Test ROC AUC': results[4],\n",
    "        'Test PR AUC': results[5]\n",
    "    }\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    tp = results[6]\n",
    "    fp = results[7]\n",
    "    tn = results[8]\n",
    "    fn = results[9]\n",
    "    \n",
    "    # Add derived metrics\n",
    "    metrics['Test F1 Score'] = 2 * (metrics['Test Precision'] * metrics['Test Recall']) / \\\n",
    "                              (metrics['Test Precision'] + metrics['Test Recall'] + 1e-7)\n",
    "    metrics['Test Specificity'] = tn / (tn + fp + 1e-7)\n",
    "    \n",
    "    for name, value in metrics.items():\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = (model.predict(test_generator) > 0.5).astype(int)\n",
    "    y_true = test_generator.classes\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, \n",
    "                              target_names=['Forged', 'Genuine'],\n",
    "                              zero_division=0))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Forged', 'Genuine'],\n",
    "                yticklabels=['Forged', 'Genuine'],\n",
    "                annot_kws={\"size\": 16})\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC and PR curves\n",
    "    y_scores = model.predict(test_generator)\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # PR Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('Receiver Operating Characteristic', fontsize=14)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, color='blue', lw=2,\n",
    "             label=f'PR Curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title('Precision-Recall Curve', fontsize=14)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate():\n",
    "    # Load data\n",
    "    train_gen, val_gen, test_gen = load_data_with_validation()\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(train_gen.classes),\n",
    "        y=train_gen.classes\n",
    "    )\n",
    "    class_weights = {i: w for i, w in enumerate(class_weights)}\n",
    "    print(\"\\nClass weights:\", class_weights)\n",
    "    \n",
    "    # Build model\n",
    "    model = build_optimized_model()\n",
    "    \n",
    "    print(\"\\n=== MODEL SUMMARY ===\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\n=== TRAINING STARTED ===\")\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=len(train_gen),\n",
    "        epochs=50,  # Increased epochs for better convergence\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=len(val_gen),\n",
    "        callbacks=get_enhanced_callbacks(),\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(model, test_gen)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d745ee-dd87-4a77-8cba-0dff862b7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOMLY CHOOSING ANY IMAGE FROM PREPROCESSED FOLDER AND DISPLAYING THE RESULT ALONG THE CHOOSEN IMAGE WITH ITS ACTUALL LABELLING ..\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt  # Replaces OpenCV for image display\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Load model with compile=False to avoid warnings\n",
    "model = load_model('best_model.h5', compile=False)\n",
    "# Recompile with minimal metrics if needed\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def get_random_image(dataset_path):\n",
    "    classes = ['real', 'forged']\n",
    "    chosen_class = random.choice(classes)\n",
    "    class_path = os.path.join(dataset_path, chosen_class)\n",
    "    \n",
    "    images = [f for f in os.listdir(class_path) \n",
    "              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    return os.path.join(class_path, random.choice(images)), chosen_class\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(224, 224))  # RGB auto-conversion\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    return np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "def predict_and_display():\n",
    "    image_path, true_label = get_random_image(\"C:/Users/nites/Desktop/svp_processed/svp_train\")\n",
    "    img_array = preprocess_image(image_path)\n",
    "    \n",
    "    prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "    predicted_label = \"real\" if prediction > 0.3 else \"forged\"\n",
    "    \n",
    "    print(f\"Image: {os.path.basename(image_path)}\")\n",
    "    print(f\"True: {true_label} | Predicted: {predicted_label} ({prediction:.4f})\")\n",
    "    print(\"âœ“ Correct\" if predicted_label == true_label else \"âœ— Incorrect\")\n",
    "    \n",
    "    # Display with matplotlib (no OpenCV dependency)\n",
    "    plt.imshow(plt.imread(image_path))\n",
    "    plt.title(f\"True: {true_label} | Predicted: {predicted_label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "predict_and_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a72341-e69c-43dc-be5a-108493fe8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "model = load_model(\"best_model.keras\")\n",
    "\n",
    "def predict(image):\n",
    "    # Convert and preprocess image\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img, (224, 224)) / 255.0\n",
    "    \n",
    "    # Get prediction\n",
    "    pred = model.predict(np.expand_dims(img, axis=0), verbose=0)[0][0]\n",
    "    confidence = max(pred, 1 - pred) * 100  # Convert to percentage\n",
    "    \n",
    "    # Determine result\n",
    "    if pred > 0.7:\n",
    "        return \"REAL SIGNATURE\", f\"{confidence:.1f}%\", \"green\"\n",
    "    else:\n",
    "        return \"FORGED SIGNATURE\", f\"{confidence:.1f}%\", \"red\"\n",
    "\n",
    "# Custom CSS\n",
    "css = \"\"\"\n",
    ".green-box {\n",
    "    background: #e6f7e6 !important; \n",
    "    border: 2px solid #4CAF50 !important;\n",
    "    padding: 20px !important;\n",
    "    border-radius: 5px !important;\n",
    "}\n",
    ".red-box {\n",
    "    background: #ffebee !important;\n",
    "    border: 2px solid #F44336 !important;\n",
    "    padding: 20px !important;\n",
    "    border-radius: 5px !important;\n",
    "}\n",
    ".result-text {\n",
    "    font-size: 20px !important;\n",
    "    font-weight: bold !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(css=css, theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"## ðŸ” Signature Verification System\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image_input = gr.Image(label=\"Upload Signature\", type=\"numpy\")\n",
    "            submit_btn = gr.Button(\"Verify\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            with gr.Group():\n",
    "                result_box = gr.Textbox(label=\"Result\", interactive=False, elem_classes=\"result-text\")\n",
    "                confidence_box = gr.Textbox(label=\"Confidence\", interactive=False)\n",
    "    \n",
    "    def update_ui(image):\n",
    "        label, confidence, color = predict(image)\n",
    "        return (\n",
    "            gr.Textbox(value=label, elem_classes=color+\"-box\"), \n",
    "            gr.Textbox(value=confidence)\n",
    "        )\n",
    "    \n",
    "    submit_btn.click(\n",
    "        fn=update_ui,\n",
    "        inputs=image_input,\n",
    "        outputs=[result_box, confidence_box]\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76fab81-cd22-4024-9429-04eaf2f53e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd2933-8a5c-413e-9a73-c8fb40e67c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
